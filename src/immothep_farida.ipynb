{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('DataScience': conda)",
   "display_name": "Python 3.7.9 64-bit ('DataScience': conda)",
   "metadata": {
    "interpreter": {
     "hash": "cbddb0c922a82b6502eade9a19b10d1eba90819ab9efda7b5a1dc2be117c2b63"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Module d'estimation de biens immobilier\n",
    "## Estimation des appartements et des maisons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Libraries import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import requests\n"
   ]
  },
  {
   "source": [
    "## 2. Loading Dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file \n",
    "df_val_fonc = pd.read_csv('../data/IN/valeursfoncieres-2019.txt', sep = '|',  decimal = ',' , encoding='UTF-8')\n",
    "\n"
   ]
  },
  {
   "source": [
    "## 3. Cleaning and Filtring Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['Code service CH' 'Reference document' '1 Articles CGI' '2 Articles CGI'\\n '3 Articles CGI' '4 Articles CGI' '5 Articles CGI' 'No disposition'\\n 'Identifiant local'] not found in axis\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-78e8e049e424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(df_val_fonc.head())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#drop empty columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_val_fonc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_val_fonc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Code service CH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Reference document'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1 Articles CGI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2 Articles CGI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3 Articles CGI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'4 Articles CGI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'5 Articles CGI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'No disposition'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Identifiant local'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(df_val_fonc.head())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#faire un groupby\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m         )\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3882\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3884\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3916\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3918\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3919\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DataScience\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5278\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5279\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Code service CH' 'Reference document' '1 Articles CGI' '2 Articles CGI'\\n '3 Articles CGI' '4 Articles CGI' '5 Articles CGI' 'No disposition'\\n 'Identifiant local'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#print(df_val_fonc.head())\n",
    "#drop empty columns \n",
    "df_val_fonc = df_val_fonc.drop(['Code service CH', 'Reference document', '1 Articles CGI', '2 Articles CGI', '3 Articles CGI', '4 Articles CGI', '5 Articles CGI', 'No disposition','Identifiant local'], axis = 1)\n",
    "#print(df_val_fonc.head())\n",
    "#faire un groupby\n",
    "df_val_fonc = df_val_fonc.groupby(['Date mutation', 'Nature mutation','Valeur fonciere','No voie','Voie','Code postal','Commune','Code departement','No plan','Type local','Code type local', 'Surface terrain'])['Surface reelle bati','Nombre pieces principales'].sum().reset_index()\n",
    "#\n",
    "df_val_fonc = df_val_fonc.drop(['Date mutation', 'No voie','No plan','Code type local'], axis = 1)\n",
    "# # lines  filter\n",
    "df_val_fonc = df_val_fonc.dropna()\n",
    "df_val_fonc.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "source": [
    "## 4. Filtering on \"Type local\" = Apartments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérere des appartements\n",
    "df_val_fonc_App = df_val_fonc.loc[(df_val_fonc['Nature mutation']==\"Vente\") & (df_val_fonc['Type local']==\"Appartement\"),:]\n",
    "df_val_fonc_App = df_val_fonc_App.drop(['Nature mutation'], axis = 1)\n",
    "\n",
    "# filtrer par rapport à la 'Valeur fonciere' et la 'Surface reelle bati'\n",
    "df_val_fonc_App.drop(df_val_fonc_App[(df_val_fonc_App['Valeur fonciere']< 7000.00)|(df_val_fonc['Valeur fonciere'].isna())].index, inplace = True)\n",
    "df_val_fonc_App.drop(df_val_fonc_App[df_val_fonc_App['Valeur fonciere']> 20000000.00].index, inplace = True)\n",
    "#\n",
    "df_val_fonc_App.drop(df_val_fonc_App[df_val_fonc_App['Surface reelle bati']< 9.00].index, inplace = True)\n"
   ]
  },
  {
   "source": [
    "## 4. Filtering on \"Type local\" = Houses"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer des maisons\n",
    "df_val_fonc_maison = df_val_fonc.loc[(df_val_fonc['Nature mutation']==\"Vente\") & (df_val_fonc['Type local']==\"Maison\"),:]\n",
    "df_val_fonc_maison = df_val_fonc_maison.drop(['Nature mutation'], axis = 1)\n",
    "\n",
    "# filtrer par rapport à la 'Valeur fonciere' et la 'Surface reelle bati'\n",
    "df_val_fonc_maison.drop(df_val_fonc_maison[(df_val_fonc_maison['Valeur fonciere']< 90000.00)|(df_val_fonc['Valeur fonciere'].isna())].index, inplace = True)\n",
    "df_val_fonc_maison.drop(df_val_fonc_maison[df_val_fonc_maison['Valeur fonciere']> 15000000.00].index, inplace = True)\n",
    "#\n",
    "df_val_fonc_maison.drop(df_val_fonc_maison[df_val_fonc_maison['Surface reelle bati']< 20.00].index, inplace = True)\n",
    "df_val_fonc_maison.drop(df_val_fonc_maison[df_val_fonc_maison['Nombre pieces principales']> 10].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "plt.scatter(df_val_fonc_App[\"Surface reelle bati\"], df_val_fonc_App[\"Valeur fonciere\"])\n",
    "plt.xlabel(\"Surface batie\")\n",
    "plt.ylabel(\"Valeur fonciere\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_corr = df_val_fonc_App.corr().round(3)\n",
    "sns.heatmap(data = matrice_corr, annot=True)"
   ]
  },
  {
   "source": [
    "## Linear regression model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "columns = df_val_fonc_App.columns.tolist()\n",
    "# Filtrer les colonnes pour supprimer celles que nous ne voulons pas.\n",
    "columns = [c for c in columns if c not in [\"Valeur fonciere\",\"Voie\", \"Commune\",\"Type local\", \"Code departement\"]]\n",
    "#stocker la variable à prédire\n",
    "target = \"Valeur fonciere\"\n",
    "# générer l'ensemble de données pour l'apprentissage, définir un état aléatoire pour reproduire les résultats\n",
    "train = df_val_fonc_App.sample(frac=0.8, random_state=1)\n",
    "\n",
    "# selectionner un autre ensemble qui n'est pas dans l'apprentissage\n",
    "test = df_val_fonc_App.loc[~df_val_fonc_App.index.isin(train.index)]\n",
    "# Initialiser la classe du modèle\n",
    "lin_model = LinearRegression()\n",
    "# Ajuster le modèle aux données d'apprentissage (fit the model to the training data)\n",
    "lin_model.fit(train[columns], train[target])\n",
    "#lin_model.fit(test[columns], test[target])\n",
    "# générer les predictions\n",
    "lin_predictions = lin_model.predict(test[columns]).round(3)\n",
    "#print(\"Predictions:\", lin_predictions)\n",
    "print('Values test : ', test[target][:5])\n",
    "print('Predict Values predict : ', lin_predictions[:5])\n",
    "# calcul d'erreur entre les prédictions et les valeurs fournies\n",
    "lin_mse = mean_squared_error(lin_predictions,test[target]).round(3)\n",
    "print(\"Computed error:\", lin_mse)\n",
    "#lin_model.score(test[columns],train[target])\n",
    "lin_model.score(test[columns], test[target])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Linear Regression model is not adapted to our dataset beacause there is correlation betwween features (Surafce reelle bati & nombre de piece principale).  \n",
    "###  So we use another model wich regression we shon va essayer l'algorithme random forest car c'est un algorithme qui peut prendre en compte les non linéarités dans les données."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5. Selecting Features and spliting the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting Features\n",
    "x = df_val_fonc_App[['Code postal','Surface reelle bati','Nombre pieces principales', 'Surface terrain']]\n",
    "# Selecting Target \n",
    "y = df_val_fonc_App[['Valeur fonciere']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle =True)\n",
    "#\n",
    "#np.isfinite(X_test).all()\n"
   ]
  },
  {
   "source": [
    "## 6. Fitting random Forest Regressor to the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = RandomForestRegressor(n_estimators = 100, min_samples_leaf = 4, random_state = 1)\n",
    "model_RF.fit(x_train, y_train)\n",
    "model_RF.fit(x_test, y_test)\n",
    "#\n",
    "lin_predictions_FR = model_RF.predict(x_test).round(3)\n",
    "#\n",
    "print('Values test : ', y_test[:5])\n",
    "print('Predict Values predict : ', lin_predictions_FR[:5])\n",
    "#lin_mse = mean_squared_error(lin_predictions, y)\n",
    "model_RF.score(x_test, y_test)"
   ]
  },
  {
   "source": [
    "## 7. Model Serialization with Pickle\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_rfg_apartment_pickle','wb') as f:\n",
    "    pickle.dump(model_RF, f)\n"
   ]
  },
  {
   "source": [
    "##  Random Forest Regressor model application on houses Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_val_fonc_maison[\"Surface reelle bati\"], df_val_fonc_maison[\"Valeur fonciere\"])\n",
    "plt.xlabel(\"Surface batie\")\n",
    "plt.ylabel(\"Valeur fonciere\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_corr = df_val_fonc_maison.corr().round(3)\n",
    "sns.heatmap(data = matrice_corr, annot=True)"
   ]
  },
  {
   "source": [
    "## .Selecting Features and spliting the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Values test :          Valeur fonciere\n59468           94450.0\n96303          139500.0\n29433          180000.0\n482196         390000.0\n146440         220000.0\nPredict Values predict :  [198549.206 181372.378 186012.306 361010.53  209636.689]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5831800044358946"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Selecting Features\n",
    "X = df_val_fonc_maison[['Code postal','Surface reelle bati','Nombre pieces principales', 'Surface terrain']]\n",
    "# Selecting Target \n",
    "Y = df_val_fonc_maison[['Valeur fonciere']]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1, shuffle =True)\n",
    "#\n",
    "#np.isfinite(X_test).all()\n",
    "Maison_RF = RandomForestRegressor(n_estimators = 100, min_samples_leaf = 4, random_state = 1)\n",
    "Maison_RF.fit(X_train, Y_train)\n",
    "Maison_RF.fit(X_test, Y_test)\n",
    "#\n",
    "Maison_predictions_RF = Maison_RF.predict(X_test).round(3)\n",
    "#\n",
    "print('Values test : ', Y_test[:5])\n",
    "print('Predict Values predict : ', Maison_predictions_RF[:5])\n",
    "#lin_mse = mean_squared_error(lin_predictions, y)\n",
    "Maison_RF.score(X_test, Y_test)"
   ]
  },
  {
   "source": [
    "## 7. Model Serialization with Pickle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_rfg_house_pickle','wb') as f1:\n",
    "    pickle.dump(Maison_RF, f1)"
   ]
  },
  {
   "source": [
    "## Predecting Value With FatsAPI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'estimation': '1285767.41 €'}\n"
     ]
    }
   ],
   "source": [
    "code_postal = 75010\n",
    "surafce_reelle = 42\n",
    "nb_piece = 2\n",
    "surface_terrain = 100\n",
    "# maision = 2, appartement =1\n",
    "type_local = 1\n",
    "\n",
    "req= {\"surafce_reelle\":80, \"nb_piece\": 4, \"surface_terrain\": 80, \"code_postal\": 75000, \"type_local\":1}\n",
    "\n",
    "response = requests.get(\"http://localhost:8000/api/estimate/\", params=req)\n",
    "print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}